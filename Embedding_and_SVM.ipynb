{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanetteFu/Message_Detect/blob/main/Embedding_and_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaOLuEc-ruaI"
      },
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv('/content/sample_data/train_clean_data.csv')\n",
        "test_data = pd.read_csv('/content/sample_data/test_clean_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgYCVXvIsNjn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9528ebd6-3932-4e19-dd54-2e18e3a6e33b"
      },
      "source": [
        "print(test_data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unnamed: 0    0\n",
            "text          0\n",
            "target        0\n",
            "hashtag       0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0zCU6S5sfuP"
      },
      "source": [
        "train_data = train_data.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAqQ_JXb6wyr"
      },
      "source": [
        "train1 = train_data.loc[train_data['target'] == 1]\n",
        "train0 = train_data.loc[train_data['target'] == 0]\n",
        "test1 = test_data.loc[test_data['target'] == 1]\n",
        "test0 = test_data.loc[test_data['target'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_DnHBYfL8cF"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tknzr = TweetTokenizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7m3OwcttM1f"
      },
      "source": [
        "train_list = train1.text.to_list()\n",
        "train_list0 = train0.text.to_list()\n",
        "train_target = train1.target.to_list()\n",
        "train0_target = train0.target.to_list()\n",
        "for i in range(0,2034):\n",
        "  train_list.append(train_list0[i])\n",
        "for i in range(0,2034):\n",
        "  train_target.append(train0_target[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUS7BFPh8oDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ebfd887d-c143-4ca8-f962-d92b57b05076"
      },
      "source": [
        "train_list[2034]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'the console war is not real console choices do # perplexing'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcDnQ_FduVOi"
      },
      "source": [
        "test_list = test1.text.to_list()\n",
        "test_list0 = test0.text.to_list()\n",
        "test_target = test1.target.to_list()\n",
        "test0_target = test0.target.to_list()\n",
        "for i in range(0,208):\n",
        "  test_list.append(test_list0[i])\n",
        "\n",
        "for i in range(0,208):\n",
        "  test_target.append(test0_target[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30UP6MAR_6c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c0cee8f3-ccae-4715-8910-064462045482"
      },
      "source": [
        "test_list[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tragic white americans that prompts so many vote candidates who will slash their ow',\n",
              " '# allahsoil wwi wwii were both waged over oil # teambts # teamsuperjunior',\n",
              " 'if you look at a problem and the first thing you thing of is color be it black or white you re pa of the problem',\n",
              " 'racism is now front and center in trumpworld these kkk folk are now out in the open # kkk # trumpworld',\n",
              " 'the revolution occurred just not how marx expected it to # teambts # teamsuperjunior']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZoJUvJl9ZIT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e21e325b-5a78-4061-93a1-525261a9aacc"
      },
      "source": [
        "len(test_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iusvkiL-mysQ"
      },
      "source": [
        "Tokenize them into words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsFFUYs2xTxu"
      },
      "source": [
        "wordlist = []\n",
        "tokenize_df = pd.DataFrame(columns=['Tokenizer'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsVA8iUjuW5a"
      },
      "source": [
        "test_wordlist = []\n",
        "tokenize_test = pd.DataFrame(columns=['Tokenizer'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onlvEUocs2LH"
      },
      "source": [
        "for i in range(0,len(train_list)):\n",
        "  temp = tknzr.tokenize(train_list[i])\n",
        "  temp = [x for x in temp if x != '#']\n",
        "  wordlist.append(temp)\n",
        "  tokenize_df = tokenize_df.append({'Tokenizer': temp}, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uPZWw3L8eAX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5b1ef61-40dd-4a28-b884-448d25794b1b"
      },
      "source": [
        "len(test_wordlist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA_C61o-ui75"
      },
      "source": [
        "for i in range(0,len(test_list)):\n",
        "  temp = tknzr.tokenize(test_list[i])\n",
        "  temp = [x for x in temp if x != '#']\n",
        "  test_wordlist.append(temp)\n",
        "  tokenize_test = tokenize_test.append({'Tokenizer': temp}, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVShAqaft1se",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "550ff4bc-3d9c-4ae6-ce55-7094dfbaec7e"
      },
      "source": [
        "tokenize_df['target'] = train_target\n",
        "tokenize_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokenizer</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[not, to, sound, but, has, her, looks, to, fal...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[zionism, is, a, form, of]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[all, happy, for, lgbtfamily, but, what, i, do...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[paul, beloy, is, still, an, issue, at, varyin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[this, is, really, telling, microaggressions, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Tokenizer  target\n",
              "0  [not, to, sound, but, has, her, looks, to, fal...       1\n",
              "1                         [zionism, is, a, form, of]       1\n",
              "2  [all, happy, for, lgbtfamily, but, what, i, do...       1\n",
              "3  [paul, beloy, is, still, an, issue, at, varyin...       1\n",
              "4  [this, is, really, telling, microaggressions, ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYJK2JvOurq4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "e187075f-75ad-469c-d140-62910e3333d7"
      },
      "source": [
        "tokenize_test['target'][208:] = test0.target[0:208]\n",
        "tokenize_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokenizer</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[tragic, white, americans, that, prompts, so, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[allahsoil, wwi, wwii, were, both, waged, over...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[if, you, look, at, a, problem, and, the, firs...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[racism, is, now, front, and, center, in, trum...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[the, revolution, occurred, just, not, how, ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Tokenizer  target\n",
              "0  [tragic, white, americans, that, prompts, so, ...       1\n",
              "1  [allahsoil, wwi, wwii, were, both, waged, over...       1\n",
              "2  [if, you, look, at, a, problem, and, the, firs...       1\n",
              "3  [racism, is, now, front, and, center, in, trum...       1\n",
              "4  [the, revolution, occurred, just, not, how, ma...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu134M7wyjst"
      },
      "source": [
        " tokenize_df.to_csv('df_tokenize.csv',encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LSF-fmqn7b_"
      },
      "source": [
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Doc2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO3U3l3Fi6hf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "7e901ac2-27fd-40b0-bcdd-dfcf4fcb2e8d"
      },
      "source": [
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(wordlist, size=100, window=5, min_count=1, workers=4)\n",
        "model.save(\"word2vec.model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4231dcdaba62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word2vec.model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'wordlist' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq5rq9jw9fzW"
      },
      "source": [
        "#average score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjiG45_rKGDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7fa938ad-1d9b-496e-d587-6d6e6b10559b"
      },
      "source": [
        "model = Word2Vec.load('/content/sample_data/word2vec.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9605UC2vNDFf"
      },
      "source": [
        "Calculate for training_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scDTfHbHPlTX"
      },
      "source": [
        "clean NA in tokenize_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUtC0pu3NsVP"
      },
      "source": [
        "import numpy as np\n",
        "total_target = tokenize_df.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQI_jvIw9dQR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "19542d4a-76e9-438f-bcf9-11eb831e865d"
      },
      "source": [
        "total_average = [0]*100\n",
        "for i in range(0,len(wordlist)):\n",
        "  sum_score = [0]*100\n",
        "  for j in range(0,len(wordlist[i])):\n",
        "    temp = model[wordlist[i][j]] \n",
        "    sum_score += temp\n",
        "  average_score = sum_score/len(wordlist[i])\n",
        "  total_average = np.vstack([total_average, average_score])\n",
        "total_average = np.delete(total_average, (0), axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIMmeA4vCQ9L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37f3faca-4ae1-4a61-dbaa-360f157d66ba"
      },
      "source": [
        "total_average.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4068, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huyMuE1tuBJe"
      },
      "source": [
        "np.savetxt(\"simple_average_train.csv\", total_average, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVc8-BGKNKPJ"
      },
      "source": [
        "Calculating for testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOqX-rfzOPQi"
      },
      "source": [
        "test_target = tokenize_test.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyz5NK1t_kZX"
      },
      "source": [
        "test_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKwVe5MYNMUT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7241e00f-36ec-441e-b71b-577cb3dd474b"
      },
      "source": [
        "test_average = [0]*100\n",
        "for i in range(0,len(test_wordlist)):\n",
        "  sum_score = [0]*100\n",
        "  count = 0\n",
        "  for j in range(0,len(test_wordlist[i])):\n",
        "    if test_wordlist[i][j] in model.wv.vocab:\n",
        "      temp = model[test_wordlist[i][j]] \n",
        "      sum_score += temp\n",
        "      count += 1\n",
        "  average_score = sum_score/count\n",
        "  test_average = np.vstack([test_average, average_score])\n",
        "test_average = np.delete(test_average, (0), axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyk4ae6W_NDK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ae7927c-b620-4553-b54c-cf31421239a8"
      },
      "source": [
        "test_average.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(416, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obruu6RDwNHw"
      },
      "source": [
        "np.savetxt(\"simple_average_test.csv\", test_average, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu7tO7Gjz500"
      },
      "source": [
        "Weighting with tf idf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFqVa1HKW7f5"
      },
      "source": [
        "for training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wyZZX20z7-g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52821fa2-bd39-404c-f88a-d51b72431faf"
      },
      "source": [
        "s = wordlist[0] \n",
        "  \n",
        "# using list comprehension \n",
        "listToStr0 = ' '.join([str(elem) for elem in s]) \n",
        "  \n",
        "print(listToStr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the console war is not real console choices do perplexing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iwgQ6oR25r6"
      },
      "source": [
        "list = []\n",
        "list.append(listToStr0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ6r4FGo2tnZ"
      },
      "source": [
        "list = []\n",
        "for i in range(0,len(wordlist)):\n",
        "  s = wordlist[i] \n",
        "  \n",
        "# using list comprehension \n",
        "  listToStr = ' '.join([str(elem) for elem in s]) \n",
        "  list.append(listToStr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X11VjK1R1kL"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "#instantiate CountVectorizer()\n",
        "cv=CountVectorizer()\n",
        "\n",
        "# this steps generates word counts for the words in your docs\n",
        "word_count_vector=cv.fit_transform(list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnJF5QUz3TkG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e296c516-d2ec-4982-c7b7-25c94090dc1d"
      },
      "source": [
        "word_count_vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28763, 35127)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWYGO9CI1Kyl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f622e6d4-af7e-4c10-a343-77115d6f36d8"
      },
      "source": [
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(word_count_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpzjHFUfXgUl"
      },
      "source": [
        "# count matrix\n",
        "count_vector=cv.transform(list)\n",
        "\n",
        "# tf-idf scores\n",
        "tf_idf_vector=tfidf_transformer.transform(count_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiBvW5Vl4e3p"
      },
      "source": [
        "feature_names = cv.get_feature_names()\n",
        "\n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcfAQPdz46K3"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acbD3HcqSuxa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "031df04b-1144-4edb-bd97-53be2f9d9827"
      },
      "source": [
        "tf_first_df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
        "tf_first_df.sort_values(by=[\"tfidf\"],ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>console</th>\n",
              "      <td>0.763487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perplexing</th>\n",
              "      <td>0.381743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>choices</th>\n",
              "      <td>0.295172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>war</th>\n",
              "      <td>0.280534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>real</th>\n",
              "      <td>0.226354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fuckwomenoffice</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fucku</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fucktrump</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fuckthisshit</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zzzzzzzz</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35127 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    tfidf\n",
              "console          0.763487\n",
              "perplexing       0.381743\n",
              "choices          0.295172\n",
              "war              0.280534\n",
              "real             0.226354\n",
              "...                   ...\n",
              "fuckwomenoffice  0.000000\n",
              "fucku            0.000000\n",
              "fucktrump        0.000000\n",
              "fuckthisshit     0.000000\n",
              "zzzzzzzz         0.000000\n",
              "\n",
              "[35127 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaqs-JXVVKmc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "b5fc4882-e4c8-4e9a-c983-fa0dbc466e6d"
      },
      "source": [
        "tfidf_average = [0]*100\n",
        "for i in range(0,len(wordlist)):\n",
        "  sum_score = [0]*100\n",
        "  for j in range(0,len(wordlist[i])):\n",
        "    temp = model[wordlist[i][j]] \n",
        "    tf_idf_weight = tf_idf_vector[i].get(wordlist[i][j])\n",
        "    sum_score += tf_idf_weight*temp\n",
        "  tfidf_average = np.vstack([tfidf_average, sum_score])\n",
        "tfidf_average = np.delete(tfidf_average, (0), axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-5eed17987537>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwordlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtf_idf_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_idf_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msum_score\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtf_idf_weight\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mtfidf_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtfidf_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_score\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: get not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFVkPbmRHmys"
      },
      "source": [
        "for testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31F86zOUHooj"
      },
      "source": [
        "test_count_vector=cv.transform(test_list)\n",
        "# tf-idf scores\n",
        "test_tf_idf_vector=tfidf_transformer.transform(test_count_vector)\n",
        "test_tfidf_average = [0]*100\n",
        "for i in range(0,len(test_wordlist)):\n",
        "  sum_score = [0]*100\n",
        "  for j in range(0,len(test_wordlist[i])):\n",
        "    temp = model[test_wordlist[i][j]] \n",
        "    tf_idf_weight = test_tf_idf_vector[i].get(test_wordlist[i][j])\n",
        "    sum_score += tf_idf_weight*temp\n",
        "  test_tfidf_average = np.vstack([test_tfidf_average, sum_score])\n",
        "test_tfidf_average = np.delete(test_tfidf_average, (0), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRUjvw0tHYu9"
      },
      "source": [
        "build logistic regression classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6ZtgbTaHexK"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logisticRegr = LogisticRegression()\n",
        "logisticRegr1 = LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NCTtGLIXGoC"
      },
      "source": [
        "fit with average weighting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmclB02myou2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "a3552ce2-2a01-4e2b-cefc-e8f6ffb43f0c"
      },
      "source": [
        "print(train_target.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-278-42dfda88e858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'isnull'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFzuxHzQA5yv"
      },
      "source": [
        "test_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTWagCDANnBx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a6853887-8929-4811-e508-8e80ceb15f9d"
      },
      "source": [
        "logisticRegr.fit(total_average, train_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBdrZbhCFvJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b5efd29-9e25-44a7-e621-efe9e1f65e13"
      },
      "source": [
        "len(test_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXHquLNZOzmp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03589ba9-0466-4e6c-b1a2-a5fda68c01c1"
      },
      "source": [
        "predictions = logisticRegr.predict(test_average)\n",
        "score = logisticRegr.score(test_average, test_target)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC4YgRwF-V_9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "eabccfdd-6a33-43da-fd30-1deceba21b3c"
      },
      "source": [
        "predictions[20:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSOL5qrO5sTp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c5852c3-4b71-4acc-bf0e-d7ef127b8da4"
      },
      "source": [
        "unique, counts = np.unique(train_target, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 2034, 1: 2034}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq_NUHY65Y-O"
      },
      "source": [
        "weight_matrix1 = logisticRegr.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aBzWcvK5d3k"
      },
      "source": [
        "np.savetxt(\"simple_average_weight_matrix.csv\", weight_matrix1, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UxmuVcEXWqB"
      },
      "source": [
        "fit with tf_idf weighting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xg_6Ll3HUZH"
      },
      "source": [
        "logisticRegr1.fit(tfidf_average, total_target)\n",
        "prediction1 = logisticRegr1.predict(test_tfidf_average)\n",
        "score1 = logisticRegr1.score(test_tfidf_average, test_target)\n",
        "print(score1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}